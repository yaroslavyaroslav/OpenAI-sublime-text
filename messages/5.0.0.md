# 5.0.0

## tldr;

I got bored and rewrote the whole thing in rust completely. There's not that much brand new features so far, but a lot of them are coming, since the core of the package is now much more reliable and less tangled. [Here it is btw](https://github.com/yaroslavyaroslav/llm_runner).

## Features

1. The core of the plugin is implemented in rust, thus it has become a way faster and reliable.
2. Context passing enhancement:
    - files/sheets passes as references now, i.e. the model always sees the actual version of the file with the changes applied.
    - they're togglable now, i.e. you pick those that you want to include, call a command on it and then all the time along they're passed to the server until you toggle them back off.
    - built in output panels content passing, e.g. build systems and lsp diagnostic outputs can be passed with a command.
3. Model picker command now supports nested list flow, thus you can switch between view modes and the models on the fly.
4. `AssistantSettings` now provides `"api_type"`, where the options are `"plain_text"`[default], `"open_ai"` and `"antropic"`[not implemented]. This is the ground work already done to provide Claude and all the rest of the custom services support in the nearest future. Please take a look at the assistant settings part if you're curious about the details.
5. Chat history and picked model now can be stored in arbitrary folder (see readme for details).
6. Functions support, there are few built in functions provided to allow model to manage the code:
    - `replace_text_with_another_text` to replace an exact text snippet with the new one, 
    - `replace_text_for_whole_file` to replace the whole file content, 
    - `read_region_content` lets a model to read the file's content, 
    - `get_working_directory_content` lets a model to obtain the project structure.
7. Phantom has new action `Add to History`, which is does what you're expecting it would â€” adds question/answer to the history if you want to continue the chat on top of it.


## Breaking changes

- `prompt_mode`: ignored and has to be deleted, use quick panel instead
- general `token` property ignored, set token for each of assistant which requires it
- `insert`/

## Installation

You have to switch to a beta branch in package control settings for this package as follow:

```js
// User/Package Control.sublime-settings

{
    "install_prereleases": [
        "OpenAI completion"
    ]
}
```

## Roadmap

1. Claude/deepseek/gemini support (i.e. strict messages order).
2. View mode goodies implementation, better chat structure, code blocks quick actions, history management.
3. Input panel to output panel for request replacement.
4. Antropic [MCP implementation](https://docs.anthropic.com/en/docs/build-with-claude/mcp)
