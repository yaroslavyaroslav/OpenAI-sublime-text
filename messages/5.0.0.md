# 5.0.0

## tldr;

I got bored and rewrote the whole thing in rust completely. There's not that much brand new features so far, but a lot of them are coming, since the core of the pacakge is now much more reliable and less tangled. Here it is [btw](https://github.com/yaroslavyaroslav/llm_runner).

## Features

1. The core of the plugin is implemented in rust, thus it has become a way faster and reliable.
2. Context passing enhancement:
    - files/sheets passes as references now, i.e. all the changes made within are preserved in the next llm request
    - they're togglable now, i.e. you pick those that you want to include, call a command and then is passes all the time along the session until you toggle them back off.
    - built in output panels contnet passing, e.g. build systems and lsp diagnostic outputs can be passed with a command.
3. AssistantSettings now provides `"api_type"`, where the options is `"plain_text"`, `"open_ai"` and `"antropic"` (not implemented). This is the ground work already done to provide claude and all the rest of the custom services support in thr nearest future. Please take a look at the asssitant settings part if you're curious about the details.
4. Chat history and picked model now can be stored in arbitrary folder.
5. Functions support[not implemented yet], there're few built in functions provided to allow model to manage the code.

## Installation

You have to switch to beta branch in package control settings for this package. You can do it as follow:

```json
// User/Package Control.sublime-settings

{
    "install_prereleases": [
        "OpenAI completion"
    ]
}
```

## Roadmap

1. Claude/deepseek/gemini support
2. View mode goodies implementation, better chat structure, code blocks quick actions, history management.
2. Input panel to output panel for request replacement.
4. Fancy picker pane support.
3. Antropic [MCP implementation](https://docs.anthropic.com/en/docs/build-with-claude/mcp)
